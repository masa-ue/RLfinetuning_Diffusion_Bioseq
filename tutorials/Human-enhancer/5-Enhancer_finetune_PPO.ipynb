{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../src/\")\n",
    "sys.path.append(\"../../src/model\")\n",
    "from src.model import ddsm as ddsm\n",
    "from src.model import ddsm_model as modeld\n",
    "from src.model.lightning_model_diffusion import LightningDiffusion as lightning_dif\n",
    "\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import wandb\n",
    "wandb.login(host=\"https://api.wandb.ai\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tk74etgu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-bush-18</strong> at: <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/tk74etgu' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/tk74etgu</a><br/> View project at: <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240720_142214-tk74etgu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tk74etgu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/wandb/run-20240720_142317-z4h199lx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/z4h199lx' target=\"_blank\">effortless-cosmos-19</a></strong> to <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/z4h199lx' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/z4h199lx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact DNA-model:v0, 1318.41MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:1.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-cosmos-19</strong> at: <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/z4h199lx' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/z4h199lx</a><br/> View project at: <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240720_142317-z4h199lx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init() # Change depending on your proejcts\n",
    "artifact = run.use_artifact('fderc_diffusion/Diffusion-DNA-RNA/DNA-model:v0')\n",
    "dir = artifact.download()\n",
    "wandb.finish()\n",
    "\n",
    "class ModelParameters:\n",
    "    diffusion_weights_file = 'artifacts/DNA-dataset:v0/steps400.cat4.speed_balance.time4.0.samples100000.pth'\n",
    "    time_schedule = \"artifacts/DNA-dataset:v0/time_dependent.npz\"\n",
    "    checkpoint_path = 'artifacts/DNA-model:v0/diffusion_unconditional_epoch=054.ckpt'\n",
    "config = ModelParameters() \n",
    "DEVICE = \"cuda:1\" # Any number is fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoreNet(\n",
       "  (embed): Sequential(\n",
       "    (0): GaussianFourierProjection()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (linear): Conv1d(4, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (3): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (4): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (5-6): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (7): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (8): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (9): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (10-11): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (12): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (13): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (14): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (15-16): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (17): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (18): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (19): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "  )\n",
       "  (denses): ModuleList(\n",
       "    (0-19): 20 x Dense(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0-19): 20 x GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "  (final): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Conv1d(256, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introduce Two Models\n",
    "score_model = lightning_dif.load_from_checkpoint(checkpoint_path= config.checkpoint_path, weight_file = config.diffusion_weights_file, time_schedule = config.time_schedule, all_class_number =1)\n",
    "score_model = score_model.model\n",
    "score_model.cuda(device = DEVICE) \n",
    "\n",
    "\n",
    "original_model = lightning_dif.load_from_checkpoint(checkpoint_path= config.checkpoint_path, weight_file = config.diffusion_weights_file, time_schedule = config.time_schedule, all_class_number =1)\n",
    "original_model = original_model.model\n",
    "original_model.cuda(device = DEVICE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact human_state_dict:latest, 939.29MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    }
   ],
   "source": [
    "# Load Reward model\n",
    "from grelu.lightning import LightningModel\n",
    "model = LightningModel.load_from_checkpoint(\"artifacts/DNA-model:v0/reward_model.ckpt\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "def new_reward_model(x):\n",
    "    x = torch.nn.functional.softmax(x /0.1, -1)\n",
    "    seq = torch.transpose(x, 1, 2) \n",
    "    return model(seq)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/wandb/run-20240720_142214-tk74etgu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/tk74etgu' target=\"_blank\">light-bush-18</a></strong> to <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/tk74etgu' target=\"_blank\">https://wandb.ai/masa136/RLfinetuning_Diffusion_Bioseq-tutorials_Human-enhancer/runs/tk74etgu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.87it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU \u0004 has a total capacity of 79.15 GiB of which 13.44 MiB is free. Process 126897 has 5.63 GiB memory in use. Process 651844 has 33.29 GiB memory in use. Process 721012 has 11.48 GiB memory in use. Including non-PyTorch memory, this process has 28.17 GiB memory in use. Of the allocated memory 24.99 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isExist:\n\u001b[1;32m      7\u001b[0m    os\u001b[38;5;241m.\u001b[39mmakedirs(save_name)\n\u001b[0;32m----> 9\u001b[0m loss_curves, eval_curves \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_reward_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_reward_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentropy_coff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/../../src/model/ddsm_PPO.py:349\u001b[0m, in \u001b[0;36mfine_tuning\u001b[0;34m(score_model, reward_model, eval_model, original_model, learning_rate, num_epoch, num_steps, accmu, length, batch_size, max_time, min_time, entropy_coff, speed_balanced, save_name, device)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Calculate pi_{new}(a)\u001b[39;00m\n\u001b[1;32m    347\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 349\u001b[0m next_mean  \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_newprob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrandom_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmin_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtime_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m                    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mspeed_balanced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeed_balanced\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m intem_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msquare(old_noise_list[random_t] \u001b[38;5;241m+\u001b[39m (next_mean \u001b[38;5;241m-\u001b[39m mean_v_list[random_t])\u001b[38;5;241m/\u001b[39mvar_list[random_t]  ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \n\u001b[1;32m    362\u001b[0m log_new_probability \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(intem_new, dim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) )\n",
      "File \u001b[0;32m/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/../../src/model/ddsm_PPO.py:295\u001b[0m, in \u001b[0;36mcalculate_newprob\u001b[0;34m(given_v, i_step, score_model, origianl_model, sample_shape, init, mask, alpha, beta, max_time, min_time, time_dilation, time_dilation_start_time, batch_size, num_steps, device, random_order, speed_balanced, speed_factor, concat_input, eps)\u001b[0m\n\u001b[1;32m    292\u001b[0m batch_time_step \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m time_step\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mscore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_time_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     score \u001b[38;5;241m=\u001b[39m score_model(torch\u001b[38;5;241m.\u001b[39mcat([x, concat_input], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), batch_time_step, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/testgrelu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/testgrelu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/../../src/model/ddsm_model.py:87\u001b[0m, in \u001b[0;36mScoreNet.forward\u001b[0;34m(self, x, t, class_number, t_ind, return_a)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#pos encoding\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block, dense, norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenses, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms):\n\u001b[0;32m---> 87\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m out\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m     89\u001b[0m         out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m out\n",
      "File \u001b[0;32m/raid/home/ueharam1/prj/RLfinetuning_Diffusion_Bioseq/tutorials/Human-enhancer/../../src/model/ddsm_model.py:65\u001b[0m, in \u001b[0;36mScoreNet.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([nn\u001b[38;5;241m.\u001b[39mGroupNorm(\u001b[38;5;241m1\u001b[39m,n) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# The swish activation function\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftplus \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftplus()\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \u0004 has a total capacity of 79.15 GiB of which 13.44 MiB is free. Process 126897 has 5.63 GiB memory in use. Process 651844 has 33.29 GiB memory in use. Process 721012 has 11.48 GiB memory in use. Including non-PyTorch memory, this process has 28.17 GiB memory in use. Of the allocated memory 24.99 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from src.model import ddsm_PPO  as fine_tune\n",
    "\n",
    "import os\n",
    "save_name = \"./log_finetune_PPO/\"\n",
    "isExist = os.path.exists(save_name)\n",
    "if not isExist:\n",
    "   os.makedirs(save_name)\n",
    "\n",
    "loss_curves, eval_curves = fine_tune.fine_tuning(score_model, new_reward_model, [new_reward_model], original_model,\n",
    "            learning_rate = 4e-3, num_epoch = 1000, length = 200, num_steps = 50, accmu = 6, \\\n",
    "            batch_size = 32, save_name = save_name, entropy_coff = 0.0,  device= DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoreNet(\n",
       "  (embed): Sequential(\n",
       "    (0): GaussianFourierProjection()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (linear): Conv1d(4, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (3): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (4): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (5-6): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (7): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (8): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (9): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (10-11): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (12): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (13): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (14): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "    (15-16): 2 x Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "    (17): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "    (18): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(64,), dilation=(16,))\n",
       "    (19): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(256,), dilation=(64,))\n",
       "  )\n",
       "  (denses): ModuleList(\n",
       "    (0-19): 20 x Dense(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0-19): 20 x GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "  (final): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Conv1d(256, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load Fine-Tuned Model \n",
    "\n",
    "time_dependent_weights = torch.tensor(np.load(config.time_schedule)['x'])\n",
    "score_finetuned_model = modeld.ScoreNet(time_dependent_weights=torch.sqrt(time_dependent_weights)) \n",
    "score_finetuned_model.load_state_dict(torch.load(\"./log_finetune2/_29.pth\")) # Change here\n",
    "score_finetuned_model.cuda(device = DEVICE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 58.89it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 63.74it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.77it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 62.93it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.43it/s]\n"
     ]
    }
   ],
   "source": [
    "### Get Samples after Fine-tune models \n",
    "\n",
    "sampler = ddsm.Euler_Maruyama_sampler\n",
    "\n",
    "\n",
    "allsamples_original = []\n",
    "for t in range(5):\n",
    "    samples=[]\n",
    "    score_finetuned_model.eval()\n",
    "    samples.append(sampler(score_finetuned_model,\n",
    "                        (200,4),\n",
    "                        batch_size=128,\n",
    "                        new_class = None,\n",
    "                        class_number = 1,\n",
    "                        strength = 10, \n",
    "                        max_time=  4.0,\n",
    "                        min_time= 1.0/400,\n",
    "                        time_dilation=1,\n",
    "                        num_steps=100, \n",
    "                        eps=1e-5,\n",
    "                        speed_balanced= True,\n",
    "                        device= DEVICE, \n",
    "                        ).cpu().detach().numpy())\n",
    "    allsamples_original.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsamples = np.concatenate(allsamples_original, axis=1)\n",
    "allsamples = allsamples[0,:,:,:]\n",
    "\n",
    "generated_samples = []\n",
    "data_loader = torch.utils.data.DataLoader(allsamples.astype(\"float32\"), batch_size = 128 , num_workers=0)\n",
    "for batch in data_loader:\n",
    "    batch = (batch > 0.5) * torch.ones_like(batch)\n",
    "    batch = torch.permute(batch, (0, 2, 1)).to(DEVICE)\n",
    "    generated_samples.append(model(batch).detach().cpu() ) \n",
    "\n",
    "generated_samples = np.concatenate(generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 59.76it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 62.88it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.85it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 56.53it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.46it/s]\n"
     ]
    }
   ],
   "source": [
    "### Get Samples from Pre-Trained Models \n",
    "\n",
    "sampler = ddsm.Euler_Maruyama_sampler\n",
    "\n",
    "allsamples_original = []\n",
    "for t in range(5):\n",
    "    samples=[]\n",
    "    score_model.eval()\n",
    "    samples.append(sampler(original_model,\n",
    "                        (200,4),\n",
    "                        batch_size=128,\n",
    "                        new_class = None,\n",
    "                        class_number = 1,\n",
    "                        strength = 10, \n",
    "                        max_time=  4.0,\n",
    "                        min_time= 1.0/400,\n",
    "                        time_dilation=1,\n",
    "                        num_steps=100, \n",
    "                        eps=1e-5,\n",
    "                        speed_balanced= True,\n",
    "                        device= DEVICE, \n",
    "                        ).cpu().detach().numpy())\n",
    "    allsamples_original.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsamples = np.concatenate(allsamples_original, axis=1)\n",
    "allsamples = allsamples[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples_before = []\n",
    "data_loader = torch.utils.data.DataLoader(allsamples.astype(\"float32\"), batch_size = 128 , num_workers=0)\n",
    "for batch in data_loader:\n",
    "    batch = (batch > 0.5) * torch.ones_like(batch)\n",
    "    batch = torch.permute(batch, (0, 2, 1)).to(DEVICE)\n",
    "    generated_samples_before.append( model(batch).detach().cpu() ) \n",
    "\n",
    "generated_samples_before = np.concatenate(generated_samples_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 8000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(80, 10))\n",
    "\n",
    "compare = np.concatenate( (generated_samples_before[:,0], generated_samples[:,0]  ), axis= 0)\n",
    "\n",
    "type1 = ['Before Fine-Tuning' for i in range(len(generated_samples_before[:,0] ))]\n",
    "#type2 = ['Generated (Strong Sig)' for i in range(len(generated_samples[:,0] ))]\n",
    "type3 = ['After Fine-Tuning ' for i in range(len(generated_samples[:,0]))]\n",
    "\n",
    "type =   type1 +  type3\n",
    "data_dict = {'type': type, 'HepG2': compare[:,0] }\n",
    "plot_data = pd.DataFrame(data_dict)\n",
    "fig = sns.catplot(data=plot_data, x = 'type', y =  'HepG2', hue=\"type\", kind=\"boxen\" )\n",
    "sns.set_context(\"paper\", rc={\"figure.figsize\": (80, 10)})\n",
    "#fig.savefig(\"../media/RNA_output_high.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRELU1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
