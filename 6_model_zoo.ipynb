{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dc9d1d-81ec-4e71-8fb4-a6502ae643bc",
   "metadata": {},
   "source": [
    "# Querying the public gReLU model zoo on Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6894061-212e-4e93-b478-f584dd2a8f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T16:44:49.871477Z",
     "iopub.status.busy": "2023-09-20T16:44:49.870856Z",
     "iopub.status.idle": "2023-09-20T16:44:49.875259Z",
     "shell.execute_reply": "2023-09-20T16:44:49.874421Z",
     "shell.execute_reply.started": "2023-09-20T16:44:49.871457Z"
    }
   },
   "source": [
    "This tutorial shows how to programmatically query our public model zoo and download models and datasets. You can also visit the model zoo in your browser at https://wandb.ai/grelu/. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b8018-a70d-4f8e-8c82-7dfe39decee5",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "- wandb projects are the main storage units for datasets and the models trained on them. The main idea is to always keep the links between the raw dataset, the preprocessed dataset and the models trained on them for reproducibility, documentation and sanity reasons.\n",
    "  \n",
    "- The ideal wandb lineage is shown below. This lineage allows us to query project-model-dataset links via the API.\n",
    "\n",
    "- Each project contains a notebook describing the details of data preprocessing, model training and model testing (e.g. performance metrics on holdout data). For models trained by us, the training logs are also available and can be seen by visiting the model zoo website. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a184da-5515-43ee-b670-1377c4cc9985",
   "metadata": {},
   "source": [
    "![image.png](lineage.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251d609b-02ba-4b13-ad81-f4fd207931a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yulai/anaconda3/envs/grelu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/yulai/anaconda3/envs/grelu/lib/python3.9/site-packages/enformer_pytorch/modeling_enformer.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  TF_GAMMAS = torch.load(str(DIR / \"precomputed\"/ \"tf_gammas.pt\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import anndata\n",
    "import grelu.resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd06263-fa50-4012-9914-d402535402fd",
   "metadata": {},
   "source": [
    "## List all available projects in the zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d741f-1809-49d1-af2e-5412be26340c",
   "metadata": {},
   "source": [
    "The `grelu.resources` module contains functions for interacting with the model zoo. First, we can list all available projects in the zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc55a93-06b9-45dd-8c0d-774c78996537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msarosavo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GM12878_dnase',\n",
       " 'demo',\n",
       " 'human-mpra-agrawal-2023',\n",
       " 'binary_atac_cell_lines',\n",
       " 'model-zoo-test',\n",
       " 'alzheimers-variant-tutorial',\n",
       " 'microglia-scatac-tutorial',\n",
       " 'human-chromhmm-fullstack',\n",
       " 'human-atac-catlas',\n",
       " 'borzoi',\n",
       " 'corces-microglia-scatac',\n",
       " 'yeast-gpra',\n",
       " 'enformer']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grelu.resources.projects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765042a-3dd5-482a-8ab4-e74aa561270f",
   "metadata": {},
   "source": [
    "We choose the 'human-atac-catlas' project to interact with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071711d-4138-4808-bc77-7ab7228f24ba",
   "metadata": {},
   "source": [
    "## List all datasets and models in a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b6647e-4bf2-4d1f-95e7-faa9655001df",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'human-atac-catlas'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a20e11-6551-4552-9978-393cefb03884",
   "metadata": {},
   "source": [
    "Individual objects such as datasets and models are stored as 'artifacts' under each project. Artifacts can be of different types, but the ones that we are generally interested in are \"dataset\" (the preprocessed dataset) and \"model\" (the trained model). We can search for these under the project of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc72de0f-b2fa-4deb-8427-c9ce07910f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grelu.resources.artifacts(project_name, type_is=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b7069-1dfd-4ec7-b7bb-0a21c5595d13",
   "metadata": {},
   "source": [
    "This tells us that there is an artifact called \"dataset\" which is of the \"dataset\" type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ef34f0-5736-40c7-b69d-f83a09e47d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grelu.resources.artifacts(project_name, type_is=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926e401-34f9-4344-b947-4362b03bf977",
   "metadata": {},
   "source": [
    "This tells us that there is an artifact called \"model\" which is of the \"model\" type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac16b8f-43c5-4efb-9d3f-831747e033c9",
   "metadata": {},
   "source": [
    "## Download a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac768f-1adc-4135-9017-026da397ceca",
   "metadata": {},
   "source": [
    "Let us now select the \"dataset\" artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44ce5d7-2fc3-413d-a4bd-4ac4d59424ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact QXJ0aWZhY3Q6ODUwODcxODM0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = grelu.resources.get_artifact(\n",
    "    name=\"dataset\",\n",
    "    project = project_name,\n",
    ")\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f1a6b-6ea3-4f8b-b045-637db746f1fd",
   "metadata": {},
   "source": [
    "We can download this artifact into a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89da86fe-a955-4c11-b04b-7b5785e082f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact dataset:latest, 202.72MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/yulai/projects/RLfinetuning_Diffusion_Bioseq/artifacts/dataset:v1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir = artifact.download()\n",
    "artifact_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc3fac-e9d4-45c2-b6e5-a5d45e7b5a5d",
   "metadata": {},
   "source": [
    "We can list the iles in this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791027f6-7633-4dcd-900e-f16c30266ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessed.h5ad']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf4b725-fa07-4622-9db8-bce6cb1adcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = anndata.read_h5ad(os.path.join(artifact_dir, 'preprocessed.h5ad'))\n",
    "ad\n",
    "\n",
    "# 导出观察（obs）元数据\n",
    "ad.obs.to_csv('obs_data.csv')\n",
    "\n",
    "# 导出变量（var）元数据\n",
    "ad.var.to_csv('var_data.csv')\n",
    "\n",
    "# 假设 ad.X 是稀疏矩阵\n",
    "import pandas as pd\n",
    "\n",
    "# 将 ad.X 转换为 DataFrame\n",
    "data_matrix_df = pd.DataFrame(ad.X.toarray(), index=ad.obs.index, columns=ad.var.index)\n",
    "\n",
    "# 将数据矩阵导出为 CSV 文件\n",
    "data_matrix_df.to_csv('data_matrix.csv')\n",
    "\n",
    "# with pd.ExcelWriter('anndata_output.xlsx') as writer:\n",
    "#     ad.obs.to_excel(writer, sheet_name='Observations')\n",
    "#     ad.var.to_excel(writer, sheet_name='Variables')\n",
    "#     data_matrix_df.to_excel(writer, sheet_name='Data Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beebf8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         0    1    2    3    4    5    6    7    8    9  ...  \\\n",
      "cell type                                                                ...   \n",
      "Follicular             1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...   \n",
      "Fibro General          1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...   \n",
      "Acinar                 1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...   \n",
      "T Lymphocyte 1 (CD8+)  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  ...   \n",
      "T lymphocyte 2 (CD4+)  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
      "\n",
      "                       1121451  1121452  1121453  1121454  1121455  1121456  \\\n",
      "cell type                                                                     \n",
      "Follicular                 1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "Fibro General              0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "Acinar                     1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "T Lymphocyte 1 (CD8+)      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "T lymphocyte 2 (CD4+)      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "                       1121457  1121458  1121459  1121460  \n",
      "cell type                                                  \n",
      "Follicular                 0.0      0.0      0.0      0.0  \n",
      "Fibro General              0.0      0.0      0.0      0.0  \n",
      "Acinar                     0.0      0.0      0.0      0.0  \n",
      "T Lymphocyte 1 (CD8+)      0.0      0.0      0.0      0.0  \n",
      "T lymphocyte 2 (CD4+)      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 1121319 columns]\n"
     ]
    }
   ],
   "source": [
    "df = ad.to_df()  # Converts ad.X to a DataFrame\n",
    "print(df.head())  # View the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28944471-5b0a-40b9-9ebe-b0dae2a075e9",
   "metadata": {},
   "source": [
    "We could download the trained model from the zoo in a similar way. However, we have an additional function to download a model from the zoo and directly load it into memory in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c3542-ee40-406f-bd17-0ff31daf149b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One-step downloading and loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e44d43-cbd1-4c56-b2d7-16691458ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model:latest, 825.03MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact human_state_dict:latest, 939.29MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n",
      "/data/yulai/anaconda3/envs/grelu/lib/python3.9/site-packages/grelu/model/models.py:680: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(Path(d) / \"human.h5\")\n"
     ]
    }
   ],
   "source": [
    "model = grelu.resources.load_model(\n",
    "    project=project_name,\n",
    "    model_name='model'\n",
    ") # that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c36bd3-4c28-4a60-aaa3-b772e4de9532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningModel(\n",
       "  (model): EnformerPretrainedModel(\n",
       "    (embedding): EnformerTrunk(\n",
       "      (conv_tower): EnformerConvTower(\n",
       "        (blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(4, 768, kernel_size=(15,), stride=(1,), padding=same)\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(768, 896, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(896, 896, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(896, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(896, 1024, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1024, 1152, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1152, 1152, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1152, 1280, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1280, 1536, kernel_size=(5,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (norm): Norm(\n",
       "                (layer): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,), padding=same)\n",
       "              (act): Activation(\n",
       "                (layer): GELU()\n",
       "              )\n",
       "              (pool): Pool(\n",
       "                (layer): AttentionPool(\n",
       "                  (pool_fn): Rearrange('b d (n p) -> b d n p', p=2)\n",
       "                  (to_attn_logits): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "              (channel_transform): ChannelTransform(\n",
       "                (layer): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transformer_tower): EnformerTransformerTower(\n",
       "        (blocks): ModuleList(\n",
       "          (0): EnformerTransformerBlock(\n",
       "            (norm): Norm(\n",
       "              (layer): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (mha): Attention(\n",
       "              (to_q): Linear(in_features=1536, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=1536, out_features=512, bias=False)\n",
       "              (to_v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (to_out): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (to_rel_k): Linear(in_features=192, out_features=512, bias=False)\n",
       "              (pos_dropout): Dropout(p=0.01, inplace=False)\n",
       "              (attn_dropout): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (dropout): Dropout(\n",
       "              (layer): Dropout(p=0.4, inplace=False)\n",
       "            )\n",
       "            (ffn): FeedForwardBlock(\n",
       "              (dense1): LinearBlock(\n",
       "                (norm): Norm(\n",
       "                  (layer): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (linear): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "                (dropout): Dropout(\n",
       "                  (layer): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (act): Activation(\n",
       "                  (layer): ReLU()\n",
       "                )\n",
       "              )\n",
       "              (dense2): LinearBlock(\n",
       "                (norm): Norm(\n",
       "                  (layer): Identity()\n",
       "                )\n",
       "                (linear): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "                (dropout): Dropout(\n",
       "                  (layer): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (act): Activation(\n",
       "                  (layer): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pointwise_conv): ConvBlock(\n",
       "        (norm): Norm(\n",
       "          (layer): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,), padding=same)\n",
       "        (act): Activation(\n",
       "          (layer): GELU()\n",
       "        )\n",
       "        (pool): Pool(\n",
       "          (layer): Identity()\n",
       "        )\n",
       "        (dropout): Dropout(\n",
       "          (layer): Identity()\n",
       "        )\n",
       "      )\n",
       "      (act): Activation(\n",
       "        (layer): GELU()\n",
       "      )\n",
       "      (crop): Crop(\n",
       "        (layer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (head): ConvHead(\n",
       "      (channel_transform): ChannelTransformBlock(\n",
       "        (norm): Norm(\n",
       "          (layer): Identity()\n",
       "        )\n",
       "        (conv): ChannelTransform(\n",
       "          (layer): Conv1d(3072, 204, kernel_size=(1,), stride=(1,), padding=same)\n",
       "        )\n",
       "        (act): Activation(\n",
       "          (layer): Identity()\n",
       "        )\n",
       "        (dropout): Dropout(\n",
       "          (layer): Identity()\n",
       "        )\n",
       "      )\n",
       "      (pool): AdaptivePool(\n",
       "        (layer): AdaptiveAvgPool1d(output_size=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       "  (val_metrics): MetricCollection(\n",
       "    (accuracy): MultilabelAccuracy()\n",
       "    (auroc): MultilabelAUROC()\n",
       "    (avgprec): MultilabelAveragePrecision()\n",
       "    (best_f1): BestF1(),\n",
       "    prefix=val_\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (accuracy): MultilabelAccuracy()\n",
       "    (auroc): MultilabelAUROC()\n",
       "    (avgprec): MultilabelAveragePrecision()\n",
       "    (best_f1): BestF1(),\n",
       "    prefix=test_\n",
       "  )\n",
       "  (transform): Identity()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafee0ab-4177-4d27-a343-995ba44e8eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
